{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import warnings\n",
    "import smtplib\n",
    "import re\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df = pd.read_csv(\"traffic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting features from date_time variable\n",
    "traffic_df['date_time'] = pd.to_datetime(traffic_df.date_time)\n",
    "traffic_df['weekday'] = traffic_df.date_time.dt.weekday\n",
    "traffic_df['date'] = traffic_df.date_time.dt.date\n",
    "traffic_df['hour'] = traffic_df.date_time.dt.hour\n",
    "traffic_df['month'] = traffic_df.date_time.dt.month\n",
    "#Monday is 0 and Sunday is 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other holidays are very sparse compared to none holidays. \n",
    "#Hence encoding the holidays as TRUE and none Holidays as FALSE\n",
    "\n",
    "def any_holiday(x):\n",
    "    if x == 'None':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "traffic_df['holiday'] = traffic_df['holiday'].map(any_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The weather_description column contains  mostly describes cloudy, clear, rain, snow, thunderstorms, fog, mist and haze. \n",
    "# Create following new columns:\n",
    "#clear - where weather description contains clear is True, else False \n",
    "#cloudy - where weather description contains clouds is True, else False\n",
    "#rainstorm - where weather description contains thunderstorm and rain is True, else False\n",
    "#fog - True where weather description contains fog else False\n",
    "#mist - True where weather description contains mist else False\n",
    "#haze - True where weather description contains haze else False\n",
    "\n",
    "# First make to lowercase\n",
    "traffic_df['weather_description'] = traffic_df['weather_description'].map(lambda x:x.lower())\n",
    "\n",
    "#Any row containing \"thunderstorm\" is replaced by \"thunderstorm\"\n",
    "traffic_df.loc[traffic_df['weather_description'].str.contains('thunderstorm'),'weather_description'] = 'rainstorm'\n",
    "traffic_df.loc[traffic_df['weather_description'].str.contains('rain') & ~traffic_df['weather_description'].str.contains('snow'),'weather_description'] = 'rainstorm'\n",
    "traffic_df.loc[traffic_df['weather_description'].str.contains('clear'),'weather_description'] = 'clear'\n",
    "traffic_df.loc[traffic_df['weather_description'].str.contains('clouds'),'weather_description'] = 'cloudy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = ['rainstorm','mist','fog','haze', 'cloudy', 'clear']\n",
    "traffic_df.loc[np.logical_not(traffic_df['weather_description'].isin(weather)),'weather_description'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\ML\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Apply feature scaling techniques\n",
    "\n",
    "traffic_df['temp'] = preprocessing.minmax_scale(traffic_df['temp'])\n",
    "traffic_df['rain_1h'] = preprocessing.minmax_scale(traffic_df['rain_1h'])\n",
    "traffic_df['snow_1h'] = preprocessing.minmax_scale(traffic_df['snow_1h'])\n",
    "traffic_df['clouds_all'] = preprocessing.minmax_scale(traffic_df['clouds_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables for these newly created categories in weather description\n",
    "traffic_df = pd.get_dummies(columns=['weather_description', 'hour', 'month', 'weekday'],data=traffic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the un-needed features\n",
    "traffic_df['targetVar'] = traffic_df['traffic_volume']\n",
    "traffic_df = traffic_df.drop(['date_time', 'date', 'traffic_volume', 'weather_main'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use variable totCol to hold the number of columns in the dataframe\n",
    "totCol = len(traffic_df.columns)\n",
    "\n",
    "# Set up variable totAttr for the total number of attribute columns\n",
    "totAttr = totCol-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targetCol variable indicates the column location of the target/class variable\n",
    "# If the first column, set targetCol to 1. If the last column, set targetCol to totCol\n",
    "# If (targetCol <> 1) and (targetCol <> totCol), be aware when slicing up the dataframes for visualization\n",
    "targetCol = totCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traffic_df.shape: (8573, 56) x_orig.shape: (8573, 55) y_orig.shape: (8573,)\n"
     ]
    }
   ],
   "source": [
    "# We create attribute-only and target-only datasets (X_original and y_original) for the modeling\n",
    "\n",
    "if targetCol == totCol:\n",
    "    x_orig = traffic_df.iloc[:,0:totAttr]\n",
    "    y_orig = traffic_df.iloc[:,totAttr]\n",
    "else:\n",
    "    x_orig = traffic_df.iloc[:,1:totCol]\n",
    "    y_orig = traffic_df.iloc[:,0]\n",
    "\n",
    "print(\"traffic_df.shape: {} x_orig.shape: {} y_orig.shape: {}\".format(traffic_df.shape, x_orig.shape, y_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random seed number for reproducible results\n",
    "seedNum = 567\n",
    "\n",
    "# Set up the number of CPU cores available for multi-thread processing\n",
    "cpu_num = 6\n",
    "\n",
    "\n",
    "# Run algorithms using 10-fold cross validation\n",
    "num_folds = 10\n",
    "scoring = 'neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_df.shape: (6429, 55) y_train_df.shape: (6429,)\n",
      "x_test_df.shape: (2144, 55) y_test_df.shape: (2144,)\n"
     ]
    }
   ],
   "source": [
    "# Use 75% of the data to train the models and the remaining for testing/validation\n",
    "\n",
    "testdata_size = 0.25\n",
    "x_train_df, x_test_df, y_train_df, y_test_df = train_test_split(x_orig, y_orig, test_size=testdata_size, random_state=seedNum)\n",
    "print(\"x_train_df.shape: {} y_train_df.shape: {}\".format(x_train_df.shape, y_train_df.shape))\n",
    "print(\"x_test_df.shape: {} y_test_df.shape: {}\".format(x_test_df.shape, y_test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (6429, 55) y_train.shape: (6429,)\n",
      "x_test.shape: (2144, 55) y_test.shape: (2144,)\n"
     ]
    }
   ],
   "source": [
    "# We finalize the training and testing datasets for the modeling activities\n",
    "x_train = x_train_df.values\n",
    "y_train = y_train_df.values\n",
    "x_test = x_test_df.values\n",
    "y_test = y_test_df.values\n",
    "print(\"x_train.shape: {} y_train.shape: {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_test.shape: {} y_test.shape: {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -220862.468328 using {'n_estimators': 400}\n",
      "-220862.468328 (51082.825358) with: {'n_estimators': 400}\n",
      "-221348.861397 (51122.278256) with: {'n_estimators': 500}\n",
      "-221589.135171 (51260.585114) with: {'n_estimators': 600}\n",
      "-221163.141190 (51723.504243) with: {'n_estimators': 700}\n",
      "-221470.097829 (51674.844952) with: {'n_estimators': 800}\n",
      "Best RMSE for the Model is: 469.96007099331104\n",
      "Model training time: 0:09:37.535190\n"
     ]
    }
   ],
   "source": [
    "# Tuning algorithm - Random Forest\n",
    "results = []\n",
    "names = []\n",
    "startTimeModule = datetime.now()\n",
    "paramGrid1 = dict(n_estimators=np.array([400, 500, 600, 700, 800]))\n",
    "model1 = RandomForestRegressor(n_jobs=cpu_num)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seedNum)\n",
    "grid1 = GridSearchCV(estimator=model1, param_grid=paramGrid1, scoring=scoring, cv=kfold)\n",
    "grid_result1 = grid1.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
    "results.append(grid_result1.cv_results_['mean_test_score'])\n",
    "names.append('RF')\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print ('Best RMSE for the Model is:', math.sqrt((grid_result1.best_score_*-1)))\n",
    "print ('Model training time:',(datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8573 entries, 0 to 8572\n",
      "Data columns (total 57 columns):\n",
      "holiday                          8573 non-null int64\n",
      "temp                             8573 non-null float64\n",
      "rain_1h                          8573 non-null float64\n",
      "snow_1h                          8573 non-null float64\n",
      "clouds_all                       8573 non-null float64\n",
      "weather_main                     8573 non-null object\n",
      "weather_description_clear        8573 non-null uint8\n",
      "weather_description_cloudy       8573 non-null uint8\n",
      "weather_description_fog          8573 non-null uint8\n",
      "weather_description_haze         8573 non-null uint8\n",
      "weather_description_mist         8573 non-null uint8\n",
      "weather_description_other        8573 non-null uint8\n",
      "weather_description_rainstorm    8573 non-null uint8\n",
      "hour_0                           8573 non-null uint8\n",
      "hour_1                           8573 non-null uint8\n",
      "hour_2                           8573 non-null uint8\n",
      "hour_3                           8573 non-null uint8\n",
      "hour_4                           8573 non-null uint8\n",
      "hour_5                           8573 non-null uint8\n",
      "hour_6                           8573 non-null uint8\n",
      "hour_7                           8573 non-null uint8\n",
      "hour_8                           8573 non-null uint8\n",
      "hour_9                           8573 non-null uint8\n",
      "hour_10                          8573 non-null uint8\n",
      "hour_11                          8573 non-null uint8\n",
      "hour_12                          8573 non-null uint8\n",
      "hour_13                          8573 non-null uint8\n",
      "hour_14                          8573 non-null uint8\n",
      "hour_15                          8573 non-null uint8\n",
      "hour_16                          8573 non-null uint8\n",
      "hour_17                          8573 non-null uint8\n",
      "hour_18                          8573 non-null uint8\n",
      "hour_19                          8573 non-null uint8\n",
      "hour_20                          8573 non-null uint8\n",
      "hour_21                          8573 non-null uint8\n",
      "hour_22                          8573 non-null uint8\n",
      "hour_23                          8573 non-null uint8\n",
      "month_1                          8573 non-null uint8\n",
      "month_2                          8573 non-null uint8\n",
      "month_3                          8573 non-null uint8\n",
      "month_4                          8573 non-null uint8\n",
      "month_5                          8573 non-null uint8\n",
      "month_6                          8573 non-null uint8\n",
      "month_7                          8573 non-null uint8\n",
      "month_8                          8573 non-null uint8\n",
      "month_9                          8573 non-null uint8\n",
      "month_10                         8573 non-null uint8\n",
      "month_11                         8573 non-null uint8\n",
      "month_12                         8573 non-null uint8\n",
      "weekday_0                        8573 non-null uint8\n",
      "weekday_1                        8573 non-null uint8\n",
      "weekday_2                        8573 non-null uint8\n",
      "weekday_3                        8573 non-null uint8\n",
      "weekday_4                        8573 non-null uint8\n",
      "weekday_5                        8573 non-null uint8\n",
      "weekday_6                        8573 non-null uint8\n",
      "targetVar                        8573 non-null int64\n",
      "dtypes: float64(4), int64(2), object(1), uint8(50)\n",
      "memory usage: 887.5+ KB\n"
     ]
    }
   ],
   "source": [
    "traffic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
